{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型参数 DecisionTreeClassifier() ：\n",
    "1. 参数:criterion='entropy'-> 使用信息熵 'gini'->使用基尼系数，通常用默认基尼系数\n",
    "2. max_depth：限制树的最大深度，在高维度低样本量时十分有用，限制过拟合，最实用的，从3开始尝试\n",
    "3. min_samples_leaf:一个节点必须包含最少的训练样本数，参数太小容易过拟合，太大容易欠拟合，从5开始使用，对类别不多的分类问题，1通常是最佳选择\n",
    "4. min_samples_split：必须包含几个样本才能分支\n",
    "5. random_state,splitter='best'/'random'默认best，即生成树时优先重要程度高的，选random则是随机，故树会更随机，相对的不容易发生过拟合，但精确度不一定会降低\n",
    "#### 两个特殊情况使用的：当样本标签极其不均衡时，如检查癌症，优先给类别少的标签更多的权重，一般不需要用，模型会自动调整\n",
    "6. class_weight 默认None\n",
    "7. min_weight_fraction_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = np.array([[-1, -2], [-2, -1], [-3, -2], [1, 3], [2, 1], [3, 2]])\n",
    "y_label = np.array([0, 1, 0, 1, 0, 1])\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf = tree_clf.fit(x_features, y_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分类器参数\n",
    "tree_clf.n_classes_\n",
    "clf.feature_importances_\n",
    "#查看各属性的重要程度\n",
    "[*zip(clf.feature_importances_,wine.feature_names)] #与list(zip(x,y))相同\n",
    "#加起来为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPc0lEQVR4nO3de5CddXnA8e+TvSWEe7MWBcZYxQuDgLJFbZmKFjSpF9TWqmOVqZ2mdrzO2I6iM1BvnaojarVTzQxMsUWtiBmZQqfqKI20imwYbjGAwIhguCwkNOS62bNP/9h1DMmG7O55s+8+m+9nZoc979n9vc87Cd+cfc979kRmIkmqa1HbA0iSumPIJak4Qy5JxRlySSrOkEtScb1t7HTZsmW5fPnyNnYtSWWtW7fukcwc3Ht7KyFfvnw5w8PDbexaksqKiHun2u6pFUkqzpBLUnGGXJKKM+SSVFwrT3ZKOngyx2FsA+Qo9J1CRF/bI+kg6zrkEbEYWAsMTK73rcy8qNt1Jc1c7v4ZufmdkFuY+IF7ERz9WWLgpW2PpoOoiVMru4CXZ+ZpwOnAioh4cQPrSpqBzF3kpvNh/EHI7ZBbIbeQm99Ddja2PZ4Ooq5DnhO2Tt7sm/zwd+NKc23XtcDYFHd0yO3fnuNhNJcaebIzInoi4ibgYeB7mXn9FF+zKiKGI2J4ZGSkid1K2tP4ZsjOFHfshvFH53wczZ1GQp6Zncw8HTgBODMiTpnia1Zn5lBmDg0O7vMKU0nd6v9dpvxhOA4jBs6a83E0dxq9/DAzHwOuBVY0ua6kA4veZ8KS1wJL9ti6BHpPhoGzW5pKc6GJq1YGgd2Z+VhELAHOAT7V9WSSZiyO/AQMnEVu/wbkLlh8HnHYHxPR0/ZoOoiauI78qcBlMfE3ZRHwzcz8jwbWlTRDEQGLVxKLV7Y9iuZQ1yHPzFuAFzQwiyRpFnyJviQVZ8glqThDLknFGXJJKs6QS1JxhlySijPkklScIZek4gy5JBVnyCWpOEMuScUZckkqzpBLUnGGXJKKM+SSVJwhl6TiDLkkFWfIJak4Qy5JxRlySSrOkEtScYZckooz5JJUnCGXpOIMuSQVZ8glqThDLknFGXJJKs6QS1JxhlySiuttewBJWuiys5HcdinsvhV6n0ssfQfR+/TG1u865BFxIvBV4DhgHFidmV/odl1JWghy98/JTX8KuQsYg923kDu/A8dcRvSf1sg+mji1MgZ8IDOfB7wYeFdEnNzAupJUXj7+CchtTKQSoAO5ndzyd43to+uQZ+YDmXnj5OePAxuA47tdV5IWhNF1U28f+xmZY1PfN0ONPtkZEcuBFwDXT3HfqogYjojhkZGRJncrSfNXLN3PHQNATyO7aCzkEXE4cCXw/szcsvf9mbk6M4cyc2hwcLCp3UrS/HbYW4HFe20cgCV/QkQ0sotGQh4RfUxE/PLM/HYTa0rSQhCH/zUsPhcYgDhi4r8DZxFHfrCxfTRx1UoAlwAbMvPi7keSpIUjoo84+rNk50EYuxt6lxM9zT6N2MR15L8PvA24NSJumtz24cy8poG1JWlBiJ7joOe4g7J21yHPzOuAZk70SJJmzJfoS1JxhlySijPkklScIZek4gy5JBVnyCWpOEMuScUZckkqzpBLUnGGXJKKM+SSVJwhl6TiDLkkFWfIJak4Qy5JxRlySSrOkEtScYZckooz5JJUnCGXpOIMuSQVZ8glqThDLknFGXJJKs6QS1JxhlySijPkklScIZek4gy5JBVnyCXNW52xDr9Yfx+P/OrRtkeZ13qbWCQiLgVeDTycmac0saakQ9t1a67nc6u+zO5dY3TGOpx0xu9w4RUf4Njjjml7tHmnqUfk/wKsaGgtSYe4e265l3942z+y5dGt7Ni6k9Gdu7n9+p9zwYpPkpltjzfvNBLyzFwLbGpiLUla84Wr2b1r7AnbOmPjbLz7Qe6++RftDDWPzdk58ohYFRHDETE8MjIyV7uVVNBDv3yE8c74Ptt7ent4dOPmFiaa3+Ys5Jm5OjOHMnNocHBwrnYrqaAzzj2V/iX9+2wf3bWbZw89s4WJ5jevWpE077z6r87lqGVH0Nf/m+sxFi8d4PXvWckxTzmqxcnmp0auWpGkJi09ain/vO7T/Punv8OPr7qBw485nDe871Wc/abfa3u0eSmaeAY4Ir4OnA0sAx4CLsrMS/b39UNDQzk8PNz1fiXpUBIR6zJzaO/tjTwiz8y3NLGOJGnmPEcuScUZckkqzpBLUnGGXJKKM+SSVJwhl6TiDLkkFWfIJak4Qy5JxRlySSrOkEtScYZckooz5JJUnCGXpOIMuSQVZ8glqThDLknFGXJJKs6QS1JxhlySijPkklScIZek4gy5JBVnyCWpOEMuScUZckkqzpBLUnGGXJKKM+SSVJwhl6TiDLkkFddIyCNiRUTcERF3RcSHmlhTkjQ9XYc8InqAfwJWAicDb4mIk7tdV5I0PU08Ij8TuCsz78nMUeAbwHkNrCtJmoYmQn48cN8et++f3PYEEbEqIoYjYnhkZKSB3UqSoJmQxxTbcp8NmaszcygzhwYHBxvYrSQJmgn5/cCJe9w+AdjYwLqSpGloIuQ3ACdFxDMioh94M3BVA+tKkqaht9sFMnMsIt4N/BfQA1yameu7nkySNC1dhxwgM68BrmliLUnSzPjKTkkqzpBLUnGGXJKKM+SSVJwhl6TiDLkkFWfIJak4Qy5JxRlySSrOkEtScYZckooz5JJUnCGXpOIMuSQVZ8glqThDLknFGXJJKs6QS1JxhlySijPkklScIZek4gy5JBVnyCWpOEMuScUZckkqzpBLUnGGXJKKM+SSVJwhl6TiDHlLsvMoOb6l7TEkLQBdhTwi3hgR6yNiPCKGmhpqIcvdtzA+soIceSn58EsY3/R2svNQ22NJKqzbR+S3AW8A1jYwy4KXnRFy0/nQuQcYBXbD6A3kpj8jc7zt8SQV1VXIM3NDZt7R1DALXe64AnL3Xls7MP4IjF7fykyS6puzc+QRsSoihiNieGRkZK52O7+M3cvEI/G95Dh0fjXn40haGA4Y8oj4fkTcNsXHeTPZUWauzsyhzBwaHByc/cSV9Z8BLJnijoS+58/1NJIWiN4DfUFmnjMXgxwKYslryG1fhs5DwK9PsSyGgZcQfc9pczRJhXn54RyKWEL81rdgyZtg0SAsOgEOfxdx9JfaHk1SYQd8RP5kIuL1wBeBQeDqiLgpM1/ZyGQLVCw6ljjqQuDCtkeRtEB0FfLMXAOsaWgWSdIseGpFkooz5JJUnCGXpOIMuSQVZ8glqThDLknFGXJJKs6QS1JxhlySijPkklScIZek4gy5JBVnyCWpOEMuScUZckkqzpBLUnGGXJKKM+SSVJwhl6TiDLkkFWfIJak4Qy5JxRlySSrOkEtScYZckooz5JJUnCGXpOIMuSQVZ8glqThDLknF9bY9wHTdf+dGvnvZtWz9v+28+FVnMPTK01i0yH+H2jS6c5T//uaPWf+/t/O0Zx3HK84/m6MHj2p7LOmQE5k5+2+O+AzwGmAUuBv488x87EDfNzQ0lMPDw9Pez/cvX8vnVn2Fzu4OnbEOi5cOcNrLTuGja/6Wnp6eWc+v2Xt881be/aIL2PTAZnZu20X/kn56e3v4zA8u4tlnPLPt8aQFKSLWZebQ3tu7fUj7PeCUzDwVuBO4oMv19rH98R18ftVXGN0xSmesA8DObbu4+Yfr+Z81P216d5qmf/3YFTz8y0fYuW0XAKM7Rtn++A4+9fYvtTyZdOjpKuSZ+d3MHJu8+RPghO5HeqKbr11PT9++j7p3btvJD752XdO70zStveLHjI2O7bP9gXseZPNDB/yhTFKDmjzJ/A7gP/d3Z0SsiojhiBgeGRmZ9qJ9A337vW/gsIEZDajm9PVP/fRKJlP+wyvp4DlgyCPi+xFx2xQf5+3xNR8BxoDL97dOZq7OzKHMHBocHJz2gKedfTKLevYdc/HSAVb+xcunvY6atfIvz6F/Sf8Tti3qWcRzX3QSRx57REtTSYemA161kpnnPNn9EXE+8GrgD7ObZ073o6+/j49f9SE+8qq/JxOyM874+Dive89KTn/ZKU3vTtP0xg+8hlvXbuDWH20Akp6eHo449nAu+Lf3tj2adMjp9qqVFcDFwEszc9rnS2Z61QrAjm07+enVN7Jtyw5eeM7zOW75U2Y4rQ6GO9fdzZ3D9/DbT1/GC8891auIpINof1etdBvyu4AB4NHJTT/JzHce6PtmE3JJOtTtL+RdvSAoM5/VzfdLkrrnSyMlqThDLknFGXJJKs6QS1JxXV21MuudRowA987y25cBjzQ4Tps8lvlnoRwHeCzzVTfH8vTM3OcVla2EvBsRMTzV5TcVeSzzz0I5DvBY5quDcSyeWpGk4gy5JBVXMeSr2x6gQR7L/LNQjgM8lvmq8WMpd45ckvREFR+RS5L2YMglqbiSIY+Ij0fELRFxU0R8NyKe1vZMsxURn4mI2yePZ01EHN32TLMREW+MiPURMR4RJS8Ti4gVEXFHRNwVER9qe57ZiohLI+LhiLit7Vm6EREnRsQPI2LD5N+t97U902xFxOKI+GlE3Dx5LB9tdP2K58gj4sjM3DL5+XuBk6fz63Pno4h4BfCDzByLiE8BZOYHWx5rxiLiecA48BXgbzKz1O8pjogeJt5A/FzgfuAG4C2Z+bNWB5uFiPgDYCvw1cws++4rEfFU4KmZeWNEHAGsA15X9M8kgKWZuTUi+oDrgPdl5k+aWL/kI/JfR3zSUqDev0aT5uINrOdCZm7IzDvanqMLZwJ3ZeY9mTkKfAM47wDfMy9l5lpgU9tzdCszH8jMGyc/fxzYABzf7lSzkxO2Tt7sm/xorFslQw4QEZ+MiPuAtwIXtj1PQ570Dax1UB0P3LfH7fspGo2FKCKWAy8Arm93ktmLiJ6IuAl4GPheZjZ2LPM25Ad60+fM/EhmnsjEGz6/u91pn1xTb2DdtukcR2ExxbayP+ktJBFxOHAl8P69fhovJTM7mXk6Ez91nxkRjZ326uodgg6mA73p8x6+BlwNXHQQx+lK229g3ZQZ/JlUdD9w4h63TwA2tjSLJk2eT74SuDwzv932PE3IzMci4lpgBdDIE9Lz9hH5k4mIk/a4+Vrg9rZm6dbkG1h/EHhtZm5ve55D2A3ASRHxjIjoB94MXNXyTIe0yScILwE2ZObFbc/TjYgY/PUVaRGxBDiHBrtV9aqVK4HnMHGVxL3AOzPzV+1ONTuzfQPr+SYiXg98ERgEHgNuysxXtjvVzETEHwGfB3qASzPzky2PNCsR8XXgbCZ+XepDwEWZeUmrQ81CRJwF/Ai4lYn/1wE+nJnXtDfV7ETEqcBlTPzdWgR8MzM/1tj6FUMuSfqNkqdWJEm/YcglqThDLknFGXJJKs6QS1JxhlySijPkklTc/wPkvksJhPESnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_features[:,0],x_features[:,1],c=y_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9565217391304348"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test,y_test)\n",
    "#给模型打分，精确性，相当于metrics.accuracy_score(y_test,test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "## 在训练集和测试集上分布利用训练好的模型进行预测\n",
    "train_predict = clf.predict(x_train)\n",
    "test_predict = clf.predict(x_test)\n",
    "## 由于决策树模型是概率预测模型（前文介绍的 p = p(y=1|x,\\theta)）,所有我们可以利用 predict_proba 函数预测其概率\n",
    "train_predict_proba = clf.predict_proba(x_train)\n",
    "test_predict_proba = clf.predict_proba(x_test)\n",
    "print('The test predict Probability of each class:\\n',test_predict_proba)\n",
    "## 其中第一列代表预测为0类的概率，第二列代表预测为1类的概率，第三列代表预测为2类的概率。\n",
    "## 利用accuracy（准确度）【预测正确的样本数目占总预测样本数目的比例】评估模型效果\n",
    "print('The accuracy of the Logistic Regression is:',metrics.accuracy_score(y_train,train_predict))\n",
    "print('The accuracy of the Logistic Regression is:',metrics.accuracy_score(y_test,test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 另一个实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3      4     5     6     7     8      9     10  \\\n",
       "0    14.23  1.71  2.43  15.6  127.0  2.80  3.06  0.28  2.29   5.64  1.04   \n",
       "1    13.20  1.78  2.14  11.2  100.0  2.65  2.76  0.26  1.28   4.38  1.05   \n",
       "2    13.16  2.36  2.67  18.6  101.0  2.80  3.24  0.30  2.81   5.68  1.03   \n",
       "3    14.37  1.95  2.50  16.8  113.0  3.85  3.49  0.24  2.18   7.80  0.86   \n",
       "4    13.24  2.59  2.87  21.0  118.0  2.80  2.69  0.39  1.82   4.32  1.04   \n",
       "..     ...   ...   ...   ...    ...   ...   ...   ...   ...    ...   ...   \n",
       "173  13.71  5.65  2.45  20.5   95.0  1.68  0.61  0.52  1.06   7.70  0.64   \n",
       "174  13.40  3.91  2.48  23.0  102.0  1.80  0.75  0.43  1.41   7.30  0.70   \n",
       "175  13.27  4.28  2.26  20.0  120.0  1.59  0.69  0.43  1.35  10.20  0.59   \n",
       "176  13.17  2.59  2.37  20.0  120.0  1.65  0.68  0.53  1.46   9.30  0.60   \n",
       "177  14.13  4.10  2.74  24.5   96.0  2.05  0.76  0.56  1.35   9.20  0.61   \n",
       "\n",
       "       11      12  0   \n",
       "0    3.92  1065.0   0  \n",
       "1    3.40  1050.0   0  \n",
       "2    3.17  1185.0   0  \n",
       "3    3.45  1480.0   0  \n",
       "4    2.93   735.0   0  \n",
       "..    ...     ...  ..  \n",
       "173  1.74   740.0   2  \n",
       "174  1.56   750.0   2  \n",
       "175  1.56   835.0   2  \n",
       "176  1.62   840.0   2  \n",
       "177  1.60   560.0   2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(wine.data),pd.DataFrame(wine.target)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wine.feature_names\n",
    "#wine.target_names\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(wine.data,wine.target,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9259259259259259"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=20,splitter='best')\n",
    "clf = clf.fit(xtrain,ytrain)\n",
    "clf.score(xtest,ytest)\n",
    "clf.apply(xtest)#返回每个测试样本所在的叶子节点的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a.pdf'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "dot_data=tree.export_graphviz(clf,feature_names=wine.feature_names,class_names=wine.target_names,filled=True,rounded=True)\n",
    "#filled:填充颜色，不纯度越低颜色越深，即gini越低颜色越深\n",
    "#rounded:圆角框\n",
    "graph=graphviz.Source(dot_data)\n",
    "graph#直接打印树\n",
    "#若想把图保存为pdf -》graph.render(名称)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何确认最优的剪枝参数-》超参数曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "for i in range(10):\n",
    "    clf=DecisionTreeClassifier(max_depth=i+1,criterion='entropy'\n",
    "                              ,random_state=30\n",
    "                              ,splitter='random'\n",
    "                              )\n",
    "    clf.fit(xtrain,train)\n",
    "    score=clf.score(xtest,ytest)\n",
    "    test.append(score)\n",
    "plt.plot(range(1,11),test,color='red',label='max_depth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
